{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "IRLu-7N3IOn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "396f1e39-eb6b-4948-cdab-cef6eb8c997f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!pip3 install -r requirements.txt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.2.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.14.6)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (2.5.9)\n",
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (1.11.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (1.0.9)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.13.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.33.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 5)) (0.20.3)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.6/dist-packages (from openpyxl->-r requirements.txt (line 6)) (1.4)\n",
            "Requirement already satisfied: et_xmlfile in /usr/local/lib/python3.6/dist-packages (from openpyxl->-r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy->-r requirements.txt (line 7)) (1.6.8)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy->-r requirements.txt (line 7)) (2.18.4)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow->-r requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow->-r requirements.txt (line 2)) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow->-r requirements.txt (line 2)) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow->-r requirements.txt (line 2)) (40.9.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy->-r requirements.txt (line 7)) (3.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy->-r requirements.txt (line 7)) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy->-r requirements.txt (line 7)) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy->-r requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy->-r requirements.txt (line 7)) (2.6)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow->-r requirements.txt (line 2)) (5.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TbpYtxIaNDJk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "''' Firstly, I am reading my train_image and train_label with the help of pickle and pandas, and then I am converting each of them\n",
        "into numpy array and then dividing my training data into training and validation set(7800 training data and 200 validation),and\n",
        "then reshaping them into 4d matrics for inputing this data into our neural-network architecture, and I had shuffled the data\n",
        "to get more randomness in it'''\n",
        "train_x = pd.read_pickle(\"train_image.pkl\")\n",
        "\n",
        "train_y = pd.read_pickle(\"train_label.pkl\")\n",
        "\n",
        "X = np.array(train_x)\n",
        "y = np.array(train_y)\n",
        "\n",
        "X, y = shuffle(X, y)\n",
        "x_train = X[:7800]\n",
        "x_test   = X[7800:]\n",
        "y_train = y[:7800]\n",
        "y_test   = y[7800:]\n",
        "\n",
        "x_train = x_train.reshape(-1,28,28,1)\n",
        "x_test = x_test.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRUWJm8iNDo2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''I used batch-size of 10 and 10 epochs for our training data, then converted each data into float type and divided it by\n",
        "255 as it is the highest RGB value for a pixel, and then I converted our output from array of labeled data\n",
        "(from 0 to nb_classes-1) to one-hot vector'''\n",
        "input_shape = (28,28,1)\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "num_classes = 7\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "raWpOkMqND60",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "'''Its time to create our CNN architecture, the one which I was using contains 2 convolutional layer, 1 Maxpooling layer, \n",
        "2 dense layer, 1 flatten layer and 2 dropouts''' \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pjMc2deANEIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2162
        },
        "outputId": "0705b480-f4be-49b4-b5d3-9ea33d5c82b1"
      },
      "cell_type": "code",
      "source": [
        "'''I have categorical_crossentropy as my loss function and adadelta optimizer, and we are fitting the training as well as the\n",
        "validation data'''\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 1,199,495\n",
            "Trainable params: 1,199,495\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 7800 samples, validate on 200 samples\n",
            "Epoch 1/50\n",
            "7800/7800 [==============================] - 23s 3ms/step - loss: 0.8783 - acc: 0.6388 - val_loss: 0.5809 - val_acc: 0.7750\n",
            "Epoch 2/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.5809 - acc: 0.7686 - val_loss: 0.5237 - val_acc: 0.7800\n",
            "Epoch 3/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.4990 - acc: 0.8017 - val_loss: 0.3944 - val_acc: 0.8650\n",
            "Epoch 4/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.4565 - acc: 0.8233 - val_loss: 0.3796 - val_acc: 0.8400\n",
            "Epoch 5/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.4225 - acc: 0.8364 - val_loss: 0.3596 - val_acc: 0.8450\n",
            "Epoch 6/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.3928 - acc: 0.8435 - val_loss: 0.3460 - val_acc: 0.8700\n",
            "Epoch 7/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.3702 - acc: 0.8571 - val_loss: 0.3202 - val_acc: 0.8700\n",
            "Epoch 8/50\n",
            "7800/7800 [==============================] - 23s 3ms/step - loss: 0.3555 - acc: 0.8624 - val_loss: 0.3065 - val_acc: 0.8800\n",
            "Epoch 9/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.3419 - acc: 0.8650 - val_loss: 0.3081 - val_acc: 0.8650\n",
            "Epoch 10/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.3255 - acc: 0.8715 - val_loss: 0.3000 - val_acc: 0.8750\n",
            "Epoch 11/50\n",
            "7800/7800 [==============================] - 23s 3ms/step - loss: 0.3064 - acc: 0.8803 - val_loss: 0.3039 - val_acc: 0.8750\n",
            "Epoch 12/50\n",
            "7800/7800 [==============================] - 23s 3ms/step - loss: 0.2910 - acc: 0.8831 - val_loss: 0.2716 - val_acc: 0.8900\n",
            "Epoch 13/50\n",
            "7800/7800 [==============================] - 23s 3ms/step - loss: 0.2751 - acc: 0.8914 - val_loss: 0.2881 - val_acc: 0.8850\n",
            "Epoch 14/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.2619 - acc: 0.9000 - val_loss: 0.2652 - val_acc: 0.8900\n",
            "Epoch 15/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.2533 - acc: 0.9041 - val_loss: 0.2691 - val_acc: 0.8950\n",
            "Epoch 16/50\n",
            "7800/7800 [==============================] - 23s 3ms/step - loss: 0.2434 - acc: 0.9022 - val_loss: 0.2897 - val_acc: 0.9000\n",
            "Epoch 17/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.2321 - acc: 0.9123 - val_loss: 0.3093 - val_acc: 0.8750\n",
            "Epoch 18/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.2105 - acc: 0.9199 - val_loss: 0.2698 - val_acc: 0.9100\n",
            "Epoch 19/50\n",
            "7800/7800 [==============================] - 23s 3ms/step - loss: 0.2075 - acc: 0.9164 - val_loss: 0.2606 - val_acc: 0.9000\n",
            "Epoch 20/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.1945 - acc: 0.9244 - val_loss: 0.2757 - val_acc: 0.8950\n",
            "Epoch 21/50\n",
            "7800/7800 [==============================] - 23s 3ms/step - loss: 0.1844 - acc: 0.9262 - val_loss: 0.2559 - val_acc: 0.9050\n",
            "Epoch 22/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.1768 - acc: 0.9332 - val_loss: 0.2790 - val_acc: 0.8800\n",
            "Epoch 23/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.1650 - acc: 0.9388 - val_loss: 0.2609 - val_acc: 0.9350\n",
            "Epoch 24/50\n",
            "7800/7800 [==============================] - 23s 3ms/step - loss: 0.1544 - acc: 0.9403 - val_loss: 0.2684 - val_acc: 0.9150\n",
            "Epoch 25/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.1531 - acc: 0.9405 - val_loss: 0.2568 - val_acc: 0.9300\n",
            "Epoch 26/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.1380 - acc: 0.9483 - val_loss: 0.2810 - val_acc: 0.9100\n",
            "Epoch 27/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.1278 - acc: 0.9527 - val_loss: 0.3103 - val_acc: 0.9250\n",
            "Epoch 28/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.1327 - acc: 0.9488 - val_loss: 0.3063 - val_acc: 0.9200\n",
            "Epoch 29/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.1215 - acc: 0.9572 - val_loss: 0.2991 - val_acc: 0.9100\n",
            "Epoch 30/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.1137 - acc: 0.9591 - val_loss: 0.3040 - val_acc: 0.9050\n",
            "Epoch 31/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.1064 - acc: 0.9596 - val_loss: 0.3291 - val_acc: 0.9100\n",
            "Epoch 32/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.1004 - acc: 0.9628 - val_loss: 0.3519 - val_acc: 0.9100\n",
            "Epoch 33/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0953 - acc: 0.9674 - val_loss: 0.3433 - val_acc: 0.9000\n",
            "Epoch 34/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0824 - acc: 0.9696 - val_loss: 0.3302 - val_acc: 0.9200\n",
            "Epoch 35/50\n",
            "7800/7800 [==============================] - 23s 3ms/step - loss: 0.0849 - acc: 0.9688 - val_loss: 0.3024 - val_acc: 0.9150\n",
            "Epoch 36/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0826 - acc: 0.9697 - val_loss: 0.3813 - val_acc: 0.9100\n",
            "Epoch 37/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0818 - acc: 0.9715 - val_loss: 0.3609 - val_acc: 0.9150\n",
            "Epoch 38/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0687 - acc: 0.9729 - val_loss: 0.3455 - val_acc: 0.9150\n",
            "Epoch 39/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0716 - acc: 0.9745 - val_loss: 0.4022 - val_acc: 0.9100\n",
            "Epoch 40/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0689 - acc: 0.9744 - val_loss: 0.3889 - val_acc: 0.9250\n",
            "Epoch 41/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0670 - acc: 0.9751 - val_loss: 0.3537 - val_acc: 0.9050\n",
            "Epoch 42/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0573 - acc: 0.9787 - val_loss: 0.3850 - val_acc: 0.9100\n",
            "Epoch 43/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0627 - acc: 0.9778 - val_loss: 0.3964 - val_acc: 0.9050\n",
            "Epoch 44/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0536 - acc: 0.9817 - val_loss: 0.4472 - val_acc: 0.9000\n",
            "Epoch 45/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0550 - acc: 0.9814 - val_loss: 0.4334 - val_acc: 0.9050\n",
            "Epoch 46/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0539 - acc: 0.9817 - val_loss: 0.3720 - val_acc: 0.9300\n",
            "Epoch 47/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0521 - acc: 0.9815 - val_loss: 0.3689 - val_acc: 0.9100\n",
            "Epoch 48/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0473 - acc: 0.9833 - val_loss: 0.4287 - val_acc: 0.9050\n",
            "Epoch 49/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0433 - acc: 0.9853 - val_loss: 0.3972 - val_acc: 0.9100\n",
            "Epoch 50/50\n",
            "7800/7800 [==============================] - 22s 3ms/step - loss: 0.0467 - acc: 0.9833 - val_loss: 0.3819 - val_acc: 0.9200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f73d28f2b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "dM9C5Nj3NEVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "37e63880-d0fa-4b7a-e8cb-09aa8706fff2"
      },
      "cell_type": "code",
      "source": [
        "# The score is evaluated on the basis of performance on validation data\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.3818643593788147\n",
            "Test accuracy: 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yzhd7vuFNP-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Here I am saving my model and my model weights\n",
        "model_json = model.to_json()\n",
        "\n",
        "with open(\"model_num.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"model_num.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "btqywrHyNQO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab52d098-c767-4ea5-ddc2-90343aa7b0d4"
      },
      "cell_type": "code",
      "source": [
        "# Here I am reading the test data using pandas and pickle\n",
        "test_x = pd.read_pickle(\"test_image.pkl\")\n",
        "X = np.array(test_x)\n",
        "\n",
        "print(X.shape)\n",
        "x_test = X.reshape(-1,28,28,1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-b8M6yg7NVtL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "db553205-6395-4441-8e46-9f636f597c98"
      },
      "cell_type": "code",
      "source": [
        "# Here I am loading my previous made CNN Model and its weights\n",
        "json_file = open('model_num.json', 'r')\n",
        "\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "loaded_model.load_weights(\"model_num.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "loaded_model.save('model_num.hdf5')\n",
        "loaded_model=load_model('model_num.hdf5')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EuKivju5NV-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6bdecd88-e57f-4241-ee17-a3c33fb404e6"
      },
      "cell_type": "code",
      "source": [
        "''' At last I am using the test data to predict the classes of the images in it and save it in a CSV file named\n",
        "himanchal_chandra.csv '''\n",
        "a = np.arange(200)\n",
        "b = loaded_model.predict_classes(x_test)\n",
        "\n",
        "b[:200]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 6, 0, 6, 6, 0, 0, 0,\n",
              "       6, 0, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 6, 0, 3, 0, 0, 0, 0, 0, 0, 6, 6, 0, 0, 0, 0, 0, 2, 0, 6, 6, 0,\n",
              "       0, 0, 0, 0, 3, 0, 6, 6, 0, 0, 0, 0, 0, 0, 3, 6, 6, 0, 0, 6, 0, 6,\n",
              "       0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3,\n",
              "       0, 0, 0, 6, 6, 0, 3, 0, 0, 0, 0, 0, 6, 0, 6, 6, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 6, 0, 0, 0, 0, 0, 6, 0, 6, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "dsr5tWDHTR8Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data1 = ['image_index','class']\n",
        "data2 = a.T\n",
        "data3 = b.T  \n",
        "\n",
        "list1 = []\n",
        "for index, i in enumerate(data2):\n",
        "\tlist2 = [i, data3[index]]\n",
        "\tlist1.append(list2)\n",
        "\n",
        "with open('himanchal_chandra.csv', 'w+', newline='') as f:\n",
        "\twr = csv.writer(f)\n",
        "\twr.writerow(data1)\n",
        "\twr.writerows(list1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}