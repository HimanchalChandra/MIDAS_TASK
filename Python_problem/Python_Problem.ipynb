{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Kh2BMmMqXfvj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "998f6e9d-ba2d-41f2-b8a0-0ea52fba5568"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt\n",
        "import tweepy\n",
        "import jsonlines\n",
        "import pandas as pd\n",
        "import openpyxl\n",
        "\n",
        "consumer_key = \"\"\n",
        "consumer_secret = \"\"\n",
        "access_token = \"\"\n",
        "access_token_secret = \"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.2.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.14.6)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (2.5.9)\n",
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (1.0.9)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (1.11.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 1)) (2.8.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.13.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.33.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 5)) (0.20.3)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.6/dist-packages (from openpyxl->-r requirements.txt (line 6)) (1.4)\n",
            "Requirement already satisfied: et_xmlfile in /usr/local/lib/python3.6/dist-packages (from openpyxl->-r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy->-r requirements.txt (line 7)) (2.18.4)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy->-r requirements.txt (line 7)) (1.6.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow->-r requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow->-r requirements.txt (line 2)) (40.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow->-r requirements.txt (line 2)) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow->-r requirements.txt (line 2)) (0.15.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy->-r requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy->-r requirements.txt (line 7)) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy->-r requirements.txt (line 7)) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy->-r requirements.txt (line 7)) (1.22)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy->-r requirements.txt (line 7)) (3.0.1)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow->-r requirements.txt (line 2)) (5.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y0QWbOIRXmVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "# Setting your access token and secret\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "# Creating the API object while passing in auth information\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pQpUfNiAXmpN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "name = \"@midasIIITD\"\n",
        "# Number of tweets to pull\n",
        "tweets = []\n",
        "# All the tweets will be appended in the tweets list\n",
        "for status in tweepy.Cursor(api.user_timeline, id=name).items():\n",
        "    tweets.append(status._json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JdDtuJsDXm2n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Now we are outputing jsonl file named as output in which all the tweets are written and stored \n",
        "with jsonlines.open('output.jsonl', mode='w') as writer:\n",
        "    writer.write(tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IZJrt4XZXrMU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "''' In this block of code, I was opening my jsonl file, and creating varies columns of required data and apending the data in\n",
        "my_demo_list and then looping the whole process to fetch data from all the tweets. One important thing in this is that I had used\n",
        "Try and except case fetching images count in the tweets, and finally I am printing all the required data through pandas\n",
        "dataframe'''\n",
        "my_demo_list = []\n",
        "\n",
        "with jsonlines.open('output.jsonl') as all_data:  \n",
        "    for x in all_data:\n",
        "        for i in x:\n",
        "            tweet_id = i['id']\n",
        "            whole_tweet = i['text']\n",
        "            favorite_count = i['favorite_count']\n",
        "            retweet_count = i['retweet_count']\n",
        "            created_at = i['created_at']\n",
        "            image_list = []\n",
        "            try:\n",
        "                for media in i['entities']['media']:\n",
        "                    image_list.append(media['media_url'])\n",
        "                    image = len(image_list)\n",
        "            except:\n",
        "                image = \"None\"        \n",
        "\n",
        "\n",
        "            del image_list[:]\n",
        "\n",
        "\n",
        "            my_demo_list.append({'tweet_id': str(tweet_id),\n",
        "                             'favorite_count': int(favorite_count),\n",
        "                             'retweet_count': int(retweet_count),\n",
        "                             'tweet_text': whole_tweet,\n",
        "                             'created_at': created_at,\n",
        "                             'image_count': image,\n",
        "                            })\n",
        "            tweet_json = pd.DataFrame(my_demo_list, columns = ['tweet_id', 'favorite_count', \n",
        "                                                       'retweet_count','tweet_text','created_at','image_count'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3qyXL3nbXraW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3247
        },
        "outputId": "e72d86ed-0771-4d46-ebd0-957f45832525"
      },
      "cell_type": "code",
      "source": [
        "# Here I am printing the dataframe\n",
        "print(tweet_json)\n",
        "# At last I am outputing an xlsx file of the required dataframe\n",
        "tweet_json.to_excel(\"output.xlsx\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                tweet_id  favorite_count  retweet_count  \\\n",
            "0    1116279671245508608               3              2   \n",
            "1    1116266017817284609               0              0   \n",
            "2    1116265886514475008               0              1   \n",
            "3    1116265789047234560               0              2   \n",
            "4    1116170212443734016               1              0   \n",
            "5    1116061280337457152               1              0   \n",
            "6    1116046513002573825               0              0   \n",
            "7    1116038332629184512               0              2   \n",
            "8    1116024512657543168               5              4   \n",
            "9    1116019868053041152               2              1   \n",
            "10   1115902611599822852               1              0   \n",
            "11   1115839682607239173               0              1   \n",
            "12   1115656899892879361               0             14   \n",
            "13   1115480571323371520               0             36   \n",
            "14   1115480504931844101               0             17   \n",
            "15   1115338057400573953               0             15   \n",
            "16   1115149324533542912              18              2   \n",
            "17   1115093836341096449               6              0   \n",
            "18   1114894970886983680               0              0   \n",
            "19   1114894886292029440               0              0   \n",
            "20   1114856195335106560               1              1   \n",
            "21   1114783695129534464               5              2   \n",
            "22   1114783273757151232               5              1   \n",
            "23   1114762841637175296               6              1   \n",
            "24   1114762141259763712               7              1   \n",
            "25   1114576370414292992               0              2   \n",
            "26   1114569315636928512              18              3   \n",
            "27   1114198161562775553              11              1   \n",
            "28   1114016105079693312               0             16   \n",
            "29   1114015987395854336               0             11   \n",
            "..                   ...             ...            ...   \n",
            "324  1027434289011421184               0            265   \n",
            "325  1027155192326709249               2              1   \n",
            "326  1027070352491302912               3              1   \n",
            "327  1027068380962910208               0              1   \n",
            "328  1026728788762099712               0             40   \n",
            "329  1026650435296190464               1              1   \n",
            "330  1026648829947310082               1              1   \n",
            "331  1026646745915117568               1              1   \n",
            "332  1026525407548297216               0              0   \n",
            "333  1026525053456797696               0            103   \n",
            "334  1026348845062483970               0              0   \n",
            "335  1025259106104307713               6              1   \n",
            "336  1024622587110772736               5              1   \n",
            "337  1024615754971328514               0              4   \n",
            "338  1024521803308261377               0              4   \n",
            "339  1024266393682759685               1              0   \n",
            "340  1024114029097246725               0            264   \n",
            "341  1023833283321257984               0              2   \n",
            "342  1023162950926790658               0             57   \n",
            "343  1023089206820655104               0            105   \n",
            "344  1023089118719266816               0              7   \n",
            "345  1023057546066710528               0              6   \n",
            "346  1022735016822857729               3              2   \n",
            "347  1022694950658396160               8              2   \n",
            "348  1021987053880455170               5              1   \n",
            "349  1021704893537574912               2              1   \n",
            "350  1021699654805729280               2              1   \n",
            "351  1021693076337618944               4              1   \n",
            "352  1021431011970670592               3              1   \n",
            "353  1021377705084739584               7              4   \n",
            "\n",
            "                                            tweet_text  \\\n",
            "0    Thank you, everyone, for submitting your solut...   \n",
            "1    @RatnRajiv @IIITDelhi @hcdiiitd @the_dhumketu ...   \n",
            "2    RT @RatnRajiv: Attending All India DIC Meet 20...   \n",
            "3    RT @hcdiiitd: #DICMeet 2019\\n@hcdiiitd spokes ...   \n",
            "4                     @rahulkanojia98 Before 14 April.   \n",
            "5    Considering several requests to extend the dea...   \n",
            "6    We will close the submission portal in 15 min....   \n",
            "7    RT @RatnRajiv: @midasIIITD @IIITDelhi @Hitkul_...   \n",
            "8    @midasIIITD lab is looking for motivated MTech...   \n",
            "9    We will close the submission portal for submit...   \n",
            "10   Clarification: Our earlier post which indicate...   \n",
            "11   RT @IIITDelhi: Applications open for MTech (CB...   \n",
            "12   RT @IIITDelhi: We are delighted to share that ...   \n",
            "13   RT @Harvard: Professor Jelani Nelson founded A...   \n",
            "14   RT @emnlp2019: For anyone interested in submit...   \n",
            "15   RT @multimediaeval: Announcing the 2019 MediaE...   \n",
            "16   Many Congratulations to @midasIIITD student, S...   \n",
            "17   @midasIIITD thanks all students who have appea...   \n",
            "18   @himanchalchandr Meanwhile, complete CV/NLP ta...   \n",
            "19   @sayangdipto123 Submit as per the guideline ag...   \n",
            "20   We request all students whose interview are sc...   \n",
            "21   Other queries: \"none of the Tweeter Apis give ...   \n",
            "22   Other queries: \"do we have to make two differe...   \n",
            "23   Other queries: \"If using Twitter api, it does ...   \n",
            "24   Response to some queries asked by students on ...   \n",
            "25   RT @kdnuggets: Top 8 #Free Must-Read #Books on...   \n",
            "26   @nupur_baghel @PennDATS Congratulation @nupur_...   \n",
            "27   We have emailed the task details to all candid...   \n",
            "28   RT @rfpvjr: Our NAACL paper on polarization in...   \n",
            "29   RT @kdnuggets: Effective Transfer Learning For...   \n",
            "..                                                 ...   \n",
            "324  RT @TensorFlow: TensorFlow 1.10.0 has been rel...   \n",
            "325  @midasIIITD is looking for motivated IIITD MTe...   \n",
            "326  @IIITDelhi @ponguru @RatnRajiv The results of ...   \n",
            "327  RT @IIITDelhi: @midasIIITD has secured rank 1 ...   \n",
            "328  RT @kdnuggets: Comparison of Top 6 Python NLP ...   \n",
            "329  Check more details of the 20th IEEE Internatio...   \n",
            "330  MR2AMC@ISM 2018 will be organized by @RatnRaji...   \n",
            "331  Our workshop proposal named, \"MR2AMC: Multimod...   \n",
            "332  @NUSComputing Congratulations Abdelhak and Pro...   \n",
            "333  RT @goodfellow_ian: One of the most anticipate...   \n",
            "334     @the_dhumketu Great to have you in @midasIIITD   \n",
            "335  Congratulation @soujanyaporia for being appoin...   \n",
            "336  @IIITDelhi @the_dhumketu Thanks team @midasIII...   \n",
            "337  RT @IIITDelhi: Congratulations @midasIIITD int...   \n",
            "338  RT @learning_pt: Profile of the 5 Indian under...   \n",
            "339  Have a look at the list of accepted papers in ...   \n",
            "340  RT @goodfellow_ian: https://t.co/hYiWI7ntyk Te...   \n",
            "341  RT @IIITDelhi: Congratulations Dr. @RatnRajiv ...   \n",
            "342  RT @ylecun: Jitendra Malik, who directs FAIR-M...   \n",
            "343  RT @kdnuggets: .@Bloomberg launches free cours...   \n",
            "344  RT @TechAtBloomberg: Missed #PyLondinium18? Wa...   \n",
            "345  RT @IIITDelhi: We are delighted to announce th...   \n",
            "346  Get ready for the annual technical fest of @II...   \n",
            "347  Congratulations Dr. @RatnRajiv and team @midas...   \n",
            "348  Congratulations MIDAS @midasIIITD intern Prakh...   \n",
            "349    MIDAS@IIITD foundation. https://t.co/LKuzyBHzjm   \n",
            "350  It feels great to be the part of @IIITDelhi. h...   \n",
            "351  Thank you, @toonzratn for designing the logo o...   \n",
            "352  We are on Facebook too. Like our page to get o...   \n",
            "353  MIDAS is a group of researchers at IIIT-Delhi ...   \n",
            "\n",
            "                         created_at image_count  \n",
            "0    Thu Apr 11 09:59:47 +0000 2019        None  \n",
            "1    Thu Apr 11 09:05:32 +0000 2019        None  \n",
            "2    Thu Apr 11 09:05:01 +0000 2019        None  \n",
            "3    Thu Apr 11 09:04:37 +0000 2019        None  \n",
            "4    Thu Apr 11 02:44:50 +0000 2019        None  \n",
            "5    Wed Apr 10 19:31:59 +0000 2019        None  \n",
            "6    Wed Apr 10 18:33:18 +0000 2019        None  \n",
            "7    Wed Apr 10 18:00:48 +0000 2019        None  \n",
            "8    Wed Apr 10 17:05:53 +0000 2019        None  \n",
            "9    Wed Apr 10 16:47:25 +0000 2019        None  \n",
            "10   Wed Apr 10 09:01:29 +0000 2019        None  \n",
            "11   Wed Apr 10 04:51:26 +0000 2019        None  \n",
            "12   Tue Apr 09 16:45:07 +0000 2019        None  \n",
            "13   Tue Apr 09 05:04:27 +0000 2019        None  \n",
            "14   Tue Apr 09 05:04:11 +0000 2019        None  \n",
            "15   Mon Apr 08 19:38:09 +0000 2019        None  \n",
            "16   Mon Apr 08 07:08:12 +0000 2019        None  \n",
            "17   Mon Apr 08 03:27:42 +0000 2019        None  \n",
            "18   Sun Apr 07 14:17:29 +0000 2019        None  \n",
            "19   Sun Apr 07 14:17:09 +0000 2019        None  \n",
            "20   Sun Apr 07 11:43:24 +0000 2019        None  \n",
            "21   Sun Apr 07 06:55:19 +0000 2019        None  \n",
            "22   Sun Apr 07 06:53:38 +0000 2019        None  \n",
            "23   Sun Apr 07 05:32:27 +0000 2019        None  \n",
            "24   Sun Apr 07 05:29:40 +0000 2019        None  \n",
            "25   Sat Apr 06 17:11:29 +0000 2019        None  \n",
            "26   Sat Apr 06 16:43:27 +0000 2019        None  \n",
            "27   Fri Apr 05 16:08:37 +0000 2019        None  \n",
            "28   Fri Apr 05 04:05:11 +0000 2019        None  \n",
            "29   Fri Apr 05 04:04:43 +0000 2019           1  \n",
            "..                              ...         ...  \n",
            "324  Thu Aug 09 05:59:57 +0000 2018        None  \n",
            "325  Wed Aug 08 11:30:56 +0000 2018        None  \n",
            "326  Wed Aug 08 05:53:48 +0000 2018           1  \n",
            "327  Wed Aug 08 05:45:58 +0000 2018        None  \n",
            "328  Tue Aug 07 07:16:33 +0000 2018           1  \n",
            "329  Tue Aug 07 02:05:12 +0000 2018        None  \n",
            "330  Tue Aug 07 01:58:49 +0000 2018        None  \n",
            "331  Tue Aug 07 01:50:33 +0000 2018        None  \n",
            "332  Mon Aug 06 17:48:23 +0000 2018        None  \n",
            "333  Mon Aug 06 17:46:59 +0000 2018           1  \n",
            "334  Mon Aug 06 06:06:47 +0000 2018        None  \n",
            "335  Fri Aug 03 05:56:33 +0000 2018        None  \n",
            "336  Wed Aug 01 11:47:15 +0000 2018           1  \n",
            "337  Wed Aug 01 11:20:07 +0000 2018        None  \n",
            "338  Wed Aug 01 05:06:47 +0000 2018        None  \n",
            "339  Tue Jul 31 12:11:52 +0000 2018        None  \n",
            "340  Tue Jul 31 02:06:26 +0000 2018        None  \n",
            "341  Mon Jul 30 07:30:51 +0000 2018        None  \n",
            "342  Sat Jul 28 11:07:11 +0000 2018        None  \n",
            "343  Sat Jul 28 06:14:09 +0000 2018        None  \n",
            "344  Sat Jul 28 06:13:48 +0000 2018        None  \n",
            "345  Sat Jul 28 04:08:21 +0000 2018        None  \n",
            "346  Fri Jul 27 06:46:44 +0000 2018        None  \n",
            "347  Fri Jul 27 04:07:31 +0000 2018        None  \n",
            "348  Wed Jul 25 05:14:35 +0000 2018        None  \n",
            "349  Tue Jul 24 10:33:23 +0000 2018        None  \n",
            "350  Tue Jul 24 10:12:34 +0000 2018        None  \n",
            "351  Tue Jul 24 09:46:26 +0000 2018           1  \n",
            "352  Mon Jul 23 16:25:05 +0000 2018        None  \n",
            "353  Mon Jul 23 12:53:15 +0000 2018        None  \n",
            "\n",
            "[354 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}